{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade gensim\n",
    "%pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chuongho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'example', 'sentence', 'for', 'converting', 'text', 'to', 'vectors', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample sentence\n",
    "sentence = \"This is an example sentence for converting text to vectors.\"\n",
    "\n",
    "# Tokenize the sentence into words\n",
    "words = word_tokenize(sentence)\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=11, vector_size=100, alpha=0.025>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.0887972e-03, -1.5679300e-03,  7.9474989e-03, ...,\n",
       "        -5.4812501e-03,  3.8142789e-03, -8.1130210e-03],\n",
       "       [-5.1591760e-03, -6.6680624e-03, -7.7762627e-03, ...,\n",
       "         5.8359844e-03,  9.3896315e-03,  3.5085476e-03],\n",
       "       [-9.5785465e-03,  8.9431154e-03,  4.1650687e-03, ...,\n",
       "         7.1182456e-03,  5.8914376e-03, -5.5806171e-03],\n",
       "       ...,\n",
       "       [ 9.4563962e-05,  3.0773198e-03, -6.8126451e-03, ...,\n",
       "         5.1259040e-04,  8.2130842e-03, -7.0190406e-03],\n",
       "       [-8.6201606e-03,  3.6659392e-03,  5.1901680e-03, ...,\n",
       "        -2.3916462e-03, -9.5106158e-03,  4.5061260e-03],\n",
       "       [-5.3622725e-04,  2.3643136e-04,  5.1033497e-03, ...,\n",
       "        -7.0415605e-03,  9.0145587e-04,  6.3925339e-03]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train a Word2Vec model\n",
    "model = Word2Vec([words], min_count=1)\n",
    "print(model)\n",
    "# show vector for one word\n",
    "vector = model.wv[words]\n",
    "vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
